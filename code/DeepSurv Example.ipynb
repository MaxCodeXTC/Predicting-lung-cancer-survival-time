{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "# Use DeepSurv from the repo\n",
    "import sys\n",
    "sys.path.append('/home/zahrael97/deepsurv')\n",
    "import deepsurv\n",
    "sys.path.append('/home/zahrael97/anaconda3/lib/python3.7/site-packages/deepsurv/deepsurv_logger.py')\n",
    "import deepsurv.deep_surv\n",
    "from deepsurv.deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "import utils\n",
    "import viz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lasagne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in dataset\n",
    "First, I read in the dataset and print the first five elements to get a sense of what the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/zahrael97/Downloads/challenge file/xtrain/data_Q0G7b5t'\n",
    "\n",
    "df_Radiomics_train = pd.read_csv(train_path + '/features/radiomics.csv',skiprows=[0,2], header=[0],index_col=0)\n",
    "\n",
    "df_clinical_train = pd.read_csv(train_path + '/features/clinical_data.csv',index_col=0)\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "df_clinical_train = df_clinical_train.fillna(df_clinical_train.mean())\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_clinical_train[\"SourceDataset\"] )\n",
    "df_clinical_train[\"SourceDataset\"]= encoder.transform(df_clinical_train[\"SourceDataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = pd.concat([df_Radiomics_train[[\"original_shape_Sphericity\", \"original_shape_SurfaceVolumeRatio\", \"original_shape_Maximum3DDiameter\",\"original_firstorder_Entropy\",\n",
    "\"original_glcm_Id\",\"original_glcm_Idm\"]],df_clinical_train[[\"SourceDataset\",\"Nstage\",\"age\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0.Event 0\n",
      "p0.SurvivalTime 1378\n"
     ]
    }
   ],
   "source": [
    "ytrain_path = '/home/zahrael97/Downloads/challenge file/ytrain'\n",
    "df_y = pd.read_csv( ytrain_path+ '/output_VSVxRFU.csv', index_col=0)\n",
    "p0 = df_y.loc[202]\n",
    "print(\"p0.Event\", p0.Event)\n",
    "print(\"p0.SurvivalTime\", p0.SurvivalTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#y_train, y_test = train_test_split(df_y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_X_train, df_y], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dataset to \"DeepSurv\" format\n",
    "DeepSurv expects a dataset to be in the form:\n",
    "\n",
    "    {\n",
    "        'x': numpy array of float32\n",
    "        'e': numpy array of int32\n",
    "        't': numpy array of float32\n",
    "        'hr': (optional) numpy array of float32\n",
    "    }\n",
    "    \n",
    "You are providing me a csv, which I read in as a pandas dataframe. Then I convert the pandas dataframe into the DeepSurv dataset format above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_shape_Sphericity</th>\n",
       "      <th>original_shape_SurfaceVolumeRatio</th>\n",
       "      <th>original_shape_Maximum3DDiameter</th>\n",
       "      <th>original_firstorder_Entropy</th>\n",
       "      <th>original_glcm_Id</th>\n",
       "      <th>original_glcm_Idm</th>\n",
       "      <th>SourceDataset</th>\n",
       "      <th>Nstage</th>\n",
       "      <th>age</th>\n",
       "      <th>SurvivalTime</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.650210</td>\n",
       "      <td>0.275228</td>\n",
       "      <td>48.559242</td>\n",
       "      <td>5.138062</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.262780</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.573079</td>\n",
       "      <td>0.240727</td>\n",
       "      <td>75.703368</td>\n",
       "      <td>4.461054</td>\n",
       "      <td>0.495719</td>\n",
       "      <td>0.439879</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.572200</td>\n",
       "      <td>379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.642913</td>\n",
       "      <td>0.200766</td>\n",
       "      <td>70.434367</td>\n",
       "      <td>3.437111</td>\n",
       "      <td>0.616607</td>\n",
       "      <td>0.581458</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66.045200</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.634469</td>\n",
       "      <td>0.323878</td>\n",
       "      <td>46.818800</td>\n",
       "      <td>4.352564</td>\n",
       "      <td>0.457545</td>\n",
       "      <td>0.391681</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>59.356600</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.584242</td>\n",
       "      <td>0.327241</td>\n",
       "      <td>53.795911</td>\n",
       "      <td>4.055700</td>\n",
       "      <td>0.544607</td>\n",
       "      <td>0.501892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>71.055400</td>\n",
       "      <td>2119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.768658</td>\n",
       "      <td>0.281441</td>\n",
       "      <td>36.619667</td>\n",
       "      <td>4.747964</td>\n",
       "      <td>0.451176</td>\n",
       "      <td>0.383987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.126600</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.366382</td>\n",
       "      <td>0.332614</td>\n",
       "      <td>122.531629</td>\n",
       "      <td>2.716180</td>\n",
       "      <td>0.684890</td>\n",
       "      <td>0.666367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.766856</td>\n",
       "      <td>946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.616308</td>\n",
       "      <td>0.224665</td>\n",
       "      <td>64.876806</td>\n",
       "      <td>2.368997</td>\n",
       "      <td>0.746369</td>\n",
       "      <td>0.735862</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.843900</td>\n",
       "      <td>559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.721570</td>\n",
       "      <td>0.605798</td>\n",
       "      <td>22.472205</td>\n",
       "      <td>5.129264</td>\n",
       "      <td>0.272701</td>\n",
       "      <td>0.192854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.703361</td>\n",
       "      <td>0.183806</td>\n",
       "      <td>67.542579</td>\n",
       "      <td>4.227597</td>\n",
       "      <td>0.484819</td>\n",
       "      <td>0.425104</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>54.694000</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     original_shape_Sphericity  original_shape_SurfaceVolumeRatio  \\\n",
       "202                   0.650210                           0.275228   \n",
       "371                   0.573079                           0.240727   \n",
       "246                   0.642913                           0.200766   \n",
       "240                   0.634469                           0.323878   \n",
       "284                   0.584242                           0.327241   \n",
       "..                         ...                                ...   \n",
       "261                   0.768658                           0.281441   \n",
       "298                   0.366382                           0.332614   \n",
       "129                   0.616308                           0.224665   \n",
       "273                   0.721570                           0.605798   \n",
       "366                   0.703361                           0.183806   \n",
       "\n",
       "     original_shape_Maximum3DDiameter  original_firstorder_Entropy  \\\n",
       "202                         48.559242                     5.138062   \n",
       "371                         75.703368                     4.461054   \n",
       "246                         70.434367                     3.437111   \n",
       "240                         46.818800                     4.352564   \n",
       "284                         53.795911                     4.055700   \n",
       "..                                ...                          ...   \n",
       "261                         36.619667                     4.747964   \n",
       "298                        122.531629                     2.716180   \n",
       "129                         64.876806                     2.368997   \n",
       "273                         22.472205                     5.129264   \n",
       "366                         67.542579                     4.227597   \n",
       "\n",
       "     original_glcm_Id  original_glcm_Idm  SourceDataset  Nstage        age  \\\n",
       "202          0.338672           0.262780              1       0  66.000000   \n",
       "371          0.495719           0.439879              0       2  64.572200   \n",
       "246          0.616607           0.581458              0       3  66.045200   \n",
       "240          0.457545           0.391681              0       2  59.356600   \n",
       "284          0.544607           0.501892              0       3  71.055400   \n",
       "..                ...                ...            ...     ...        ...   \n",
       "261          0.451176           0.383987              0       0  87.126600   \n",
       "298          0.684890           0.666367              0       0  68.766856   \n",
       "129          0.746369           0.735862              0       1  59.843900   \n",
       "273          0.272701           0.192854              1       0  70.000000   \n",
       "366          0.484819           0.425104              0       3  54.694000   \n",
       "\n",
       "     SurvivalTime  Event  \n",
       "202          1378      0  \n",
       "371           379      1  \n",
       "246           573      1  \n",
       "240           959      0  \n",
       "284          2119      0  \n",
       "..            ...    ...  \n",
       "261          1540      0  \n",
       "298           946      0  \n",
       "129           559      0  \n",
       "273          1952      0  \n",
       "366           858      0  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_col is the header in the df that represents the 'Event / Status' indicator\n",
    "# time_col is the header in the df that represents the event time\n",
    "def dataframe_to_deepsurv_ds(df_train, event_col = 'Event', time_col = 'SurvivalTime'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df_train[event_col].values.astype(np.int32)\n",
    "    t = df_train[time_col].values.astype(np.float32)\n",
    "\n",
    "    # Extract the patient's covariates as a numpy array\n",
    "    x_df = df_train.drop([event_col, time_col], axis = 1)\n",
    "    x = x_df.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "# If the headers of the csv change, you can replace the values of \n",
    "# 'event_col' and 'time_col' with the names of the new headers\n",
    "# You can also use this function on your training dataset, validation dataset, and testing dataset\n",
    "train_data = dataframe_to_deepsurv_ds(df_train, event_col = 'Event', time_col= 'SurvivalTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([[ 0.65021026,  0.27522776, 48.559242  , ...,  1.        ,\n",
       "          0.        , 66.        ],\n",
       "        [ 0.57307863,  0.24072683, 75.70337   , ...,  0.        ,\n",
       "          2.        , 64.5722    ],\n",
       "        [ 0.64291304,  0.20076598, 70.434364  , ...,  0.        ,\n",
       "          3.        , 66.0452    ],\n",
       "        ...,\n",
       "        [ 0.61630803,  0.22466502, 64.87681   , ...,  0.        ,\n",
       "          1.        , 59.8439    ],\n",
       "        [ 0.72157025,  0.6057985 , 22.472204  , ...,  1.        ,\n",
       "          0.        , 70.        ],\n",
       "        [ 0.7033614 ,  0.18380603, 67.54258   , ...,  0.        ,\n",
       "          3.        , 54.694     ]], dtype=float32),\n",
       " 'e': array([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 't': array([1378.,  379.,  573.,  959., 2119.,  706.,   78., 1369.,  197.,\n",
       "         196., 1126.,  100.,  360.,  683.,  195., 1849.,  375.,   25.,\n",
       "         685.,  377.,  754.,  336., 1671., 1357.,  907.,  132.,  988.,\n",
       "         659., 1886., 1167., 1503.,  582.,  646., 2158.,  525., 1153.,\n",
       "         508., 1991., 1823., 1488.,  687., 2178.,  527., 1913.,   86.,\n",
       "         312.,  739., 1588.,  691., 1009.,  911.,  433.,  405., 1476.,\n",
       "         113.,  303., 3500.,  756.,  193., 2141., 1425., 1282.,  259.,\n",
       "         463.,  516.,   14., 1248.,  209.,  409., 2148., 1015.,  173.,\n",
       "         220.,  714., 1272.,  632.,   96.,  515.,  244., 1521.,   33.,\n",
       "         512.,   20.,  257., 1280.,  921., 2010.,   48.,   77.,  923.,\n",
       "         136., 1972.,  491.,  131., 2298.,  756.,  456., 1962., 1838.,\n",
       "         273.,  342.,  456.,  141.,  340.,   65.,  903.,  754., 1540.,\n",
       "         120.,  213.,  118.,   24.,  545.,  325.,  401.,  638.,  896.,\n",
       "         472.,  258., 1392.,  441.,  361.,  601.,  244., 2600.,  759.,\n",
       "         815.,  636.,  703.,   76.,  154.,  300., 1976., 1028.,  652.,\n",
       "          79.,  128.,  886., 3251., 1555.,  211., 1867.,  143.,  706.,\n",
       "         635., 2330.,  588.,  375.,  134.,  448., 1393.,  524., 1145.,\n",
       "         454.,  287.,  192., 1475.,  728.,  465.,  442.,  291.,  301.,\n",
       "        2176.,  159., 2145.,   31.,  183.,  426.,  865.,  742.,   85.,\n",
       "          43., 1238., 2297., 1401., 1070., 1370., 1174.,  120.,  568.,\n",
       "         515.,   71., 1309.,  261.,   50., 1213.,  327., 1670.,  316.,\n",
       "         493.,   21.,  476., 1172.,  515.,  317., 1458., 1359.,   87.,\n",
       "         161.,  182., 1980.,   98.,  487.,  457.,  997., 1002.,  321.,\n",
       "         258., 1995.,  528., 2165.,  618.,  309.,  818.,  791.,  510.,\n",
       "         910., 2240., 1315., 2229., 1076.,  303.,  629., 1435.,  192.,\n",
       "         666.,  155.,  177., 1384.,  293., 1814., 3078.,  825.,  131.,\n",
       "        1099.,  897., 1447.,   98., 2309., 1315., 1141.,  470., 1856.,\n",
       "         130., 2515.,  370.,  799.,  267.,  903.,   66.,  965., 1834.,\n",
       "        1190.,  797.,  210.,  173.,  991., 1548.,  421.,  763., 2140.,\n",
       "         539., 3222., 1189., 1523., 2115.,  316.,  575., 1810.,  319.,\n",
       "        2528.,  529.,  132.,  315., 1216.,  439., 2408., 1134.,  265.,\n",
       "         639., 1971., 1295.,  374.,  723., 1209.,  818., 1456.,  166.,\n",
       "        1279.,  928.,  104.,  632., 2212., 3259.,  642., 1540.,  946.,\n",
       "         559., 1952.,  858.], dtype=float32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now once you have your dataset all formatted, define you hyper_parameters as a Python dictionary. \n",
    "I'll provide you with some example hyper-parameters, but you should replace the values once you tune them to your specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'L2_reg': 10.0,\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.4,\n",
    "    'hidden_layers_sizes': [25, 25],\n",
    "    'learning_rate': 1e-05,\n",
    "    'lr_decay': 0.001,\n",
    "    'momentum': 0.9,\n",
    "    'n_in': train_data['x'].shape[1],\n",
    "    'standardize': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you prepared your dataset, and defined your hyper-parameters. Now it's time to train DeepSurv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-10 19:35:15,093 - Training step 0/2000    |                         | - loss: 19.4218 - ci: 0.4802\n",
      "2020-02-10 19:35:44,946 - Training step 250/2000  |***                      | - loss: 10.2858 - ci: 0.5593\n",
      "2020-02-10 19:36:13,675 - Training step 500/2000  |******                   | - loss: 6.9643 - ci: 0.5709\n",
      "2020-02-10 19:36:40,628 - Training step 750/2000  |*********                | - loss: 5.7963 - ci: 0.5861\n",
      "2020-02-10 19:37:13,349 - Training step 1000/2000 |************             | - loss: 5.3891 - ci: 0.6093\n",
      "2020-02-10 19:37:45,904 - Training step 1250/2000 |***************          | - loss: 5.2604 - ci: 0.6260\n",
      "2020-02-10 19:38:17,252 - Training step 1500/2000 |******************       | - loss: 5.1971 - ci: 0.6469\n",
      "2020-02-10 19:38:46,720 - Training step 1750/2000 |*********************    | - loss: 5.1803 - ci: 0.6608\n",
      "2020-02-10 19:39:18,530 - Finished Training with 2000 iterations in 243.54s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of DeepSurv using the hyperparams defined above\n",
    "model = deepsurv.DeepSurv(**hyperparams)\n",
    "# DeepSurv can now leverage TensorBoard to monitor training and validation\n",
    "# This section of code is optional. If you don't want to use the tensorboard logger\n",
    "# Uncomment the below line, and comment out the other three lines: \n",
    "# logger = None\n",
    "\n",
    "experiment_name = 'test_experiment_sebastian'\n",
    "logdir = './logs/tensorboard/'\n",
    "logger = TensorboardLogger(experiment_name, logdir=logdir)\n",
    "\n",
    "# Now we train the model\n",
    "update_fn=lasagne.updates.nesterov_momentum # The type of optimizer to use. \\\n",
    "                                            # Check out http://lasagne.readthedocs.io/en/latest/modules/updates.html \\\n",
    "                                            # for other optimizers to use\n",
    "n_epochs = 2000\n",
    "\n",
    "# If you have validation data, you can add it as the second parameter to the function\n",
    "metrics = model.train(train_data, n_epochs=n_epochs, logger=logger, update_fn=update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/home/zahrael97/Downloads/challenge file/xtest/data_9Cbe5hx'\n",
    "df_Radiomics_test = pd.read_csv(test_path +'/features/radiomics.csv',skiprows=[0,2], header=[0],index_col=0)\n",
    "df_clinical_test = pd.read_csv(test_path + '/features/clinical_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical_test = df_clinical_test.fillna(df_clinical_test.mean())\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_clinical_test[\"SourceDataset\"])\n",
    "df_clinical_test[\"SourceDataset\"] = encoder.transform(df_clinical_test[\"SourceDataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test = pd.concat([df_Radiomics_test[[\"original_shape_Sphericity\", \"original_shape_SurfaceVolumeRatio\", \"original_shape_Maximum3DDiameter\",\"original_firstorder_Entropy\",\n",
    "\"original_glcm_Id\",\"original_glcm_Idm\"]],df_clinical_test[[\"SourceDataset\",\"Nstage\",\"age\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train C-Index: (1999, 0.6700196115644967)\n"
     ]
    }
   ],
   "source": [
    "# Print the final metrics\n",
    "print('Train C-Index:', metrics['c-index'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = dataframe_to_deepsurv_ds(df_X_test, event_col = 'Event', time_col= 'SurvivalTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_test = model.train(test_data, n_epochs=n_epochs, logger=logger, update_fn=update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final metrics\n",
    "#print('Train C-Index:', metrics_test['c-index'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
